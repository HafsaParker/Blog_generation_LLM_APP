# Blog_generation_LLM_APP
This repo contains the basics of Blog generation app using LLama 2 and hugging face API on local machine. 
# Getting Started
1. Download the quantized LLama2 model from hugging face.  
   *https://huggingface.co/TheBloke/Llama-2-7B-Chat-GGML/tree/main*  
   (please download the latest version. As for now my version selection is lat one 7.16gb model)
2. Create a Main Folder and than create another sub folder "models" and place the bin file inside it.
3. Open VS code and create a requirement.txt.
4. Create a Virtual Environment :
   1.  python3 -m venv venv
   
